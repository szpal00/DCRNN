{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    from torch.utils.data import Dataset\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torch.utils.data import TensorDataset\n",
    "    import networkx as nx\n",
    "    from karateclub import DeepWalk, NetMF, GLEE, Node2Vec, Diff2Vec\n",
    "    from torchmetrics import MeanAbsolutePercentageError\n",
    "    import matplotlib.pyplot as plt\n",
    "    from argparse import ArgumentParser\n",
    "    import os\n",
    "    #from torchsummary import summary\n",
    "    from dataset import *\n",
    "    from models import *\n",
    "    \n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--accelerator', type=str, default=\"gpu\")\n",
    "    parser.add_argument('--lr', type=float, default=0.01)\n",
    "    parser.add_argument('--batch_size', type=int, default=32)\n",
    "    parser.add_argument('--max_epochs', type=int, default=75)\n",
    "    parser.add_argument('--device_num', type=int, default=0)\n",
    "    parser.add_argument('--model', type=str, default='dense')\n",
    "    parser.add_argument('--embedding', type=str, default='all')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    accelerator = args.accelerator\n",
    "    lr = args.lr\n",
    "    batch_size = args.batch_size\n",
    "    max_epochs = args.max_epochs\n",
    "    device_num = args.device_num\n",
    "    model = args.model\n",
    "    embedding = args.embedding\n",
    "    \n",
    "    \n",
    "    \n",
    "    adj_mtx = nx.read_gpickle(\"git/DCRNN/data/sensor_graph/adj_mx.pkl\")[2]\n",
    "    adj_mtx = nx.from_numpy_matrix(np.matrix(adj_mtx))\n",
    "    deepwalk = DeepWalk()\n",
    "    glee = GLEE()\n",
    "    netmf = NetMF()\n",
    "    node2vec = Node2Vec()\n",
    "    diff2vec = Diff2Vec()\n",
    "    \n",
    "    embeddings = {'deepwalk':deepwalk,'glee':glee,'netmf':netmf,'diff2vec':diff2vec,'none':None}\n",
    "    if embedding == 'all':\n",
    "        embedding_list = [deepwalk, glee, netmf, diff2vec, None]\n",
    "    else:\n",
    "        embedding_list = [embeddings[embedding]]\n",
    "        \n",
    "        \n",
    "    LSTMtrainset = LSTMDataset(np.load('data/METR-LA/train.npz'), adj_mtx = adj_mtx, embedding = deepwalk, scaling = True)\n",
    "    LSTMtestset = LSTMDataset(np.load('data/METR-LA/test.npz'), adj_mtx = adj_mtx, embedding = deepwalk,scaling = True)\n",
    "    LSTMvalset = LSTMDataset(np.load('data/METR-LA/val.npz'), adj_mtx = adj_mtx, embedding = deepwalk,scaling = True)\n",
    "    \n",
    "    use_cuda = True\n",
    "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "    for embedding in embedding_list:\n",
    "        for scaling in (True, False):\n",
    "            print(f\"Embedding: {embedding} | Scaling: {scaling}\")\n",
    "            LSTMtrainset.set_embedding(embedding)\n",
    "            LSTMtestset.set_embedding(embedding)\n",
    "            LSTMvalset.set_embedding(embedding)\n",
    "            LSTMtrainset.set_scale(scaling)\n",
    "            LSTMtestset.set_scale(scaling)\n",
    "            LSTMvalset.set_scale(scaling)\n",
    "\n",
    "            if embedding:\n",
    "                if embedding == glee:\n",
    "                    features = 2+embedding.dimensions+1\n",
    "                else:\n",
    "                    features = 2+embedding.dimensions\n",
    "            else:\n",
    "                features = 2\n",
    "            densemodel = DenseModel((12,features,207), 2*207, batch_size=batch_size).to(device)\n",
    "            optimizer =  torch.optim.Adam(densemodel.parameters(), 0.01, amsgrad = True, weight_decay=0)  \n",
    "            #optimizer = torch.optim.SGD(lstmmodel.parameters(), lr=0.1, momentum=0.1)\n",
    "\n",
    "            for i in range(max_epochs):\n",
    "                densemodel, trainpred, traintruth, scores = train(model=densemodel, optimizer=optimizer, trainset=LSTMtrainset, batch_size=batch_size, current_epoch=i, lstm=False)\n",
    "                pred, truth, scores = evaluate(model=densemodel, optimizer=optimizer, batch_size=batch_size, testset=LSTMvalset,current_epoch=i, lstm=False)\n",
    "            print(\"Test:\")\n",
    "            pred, truth, scores = evaluate(model=densemodel, optimizer=optimizer, batch_size=batch_size, testset=LSTMtestset,current_epoch=i, lstm=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
